#PROJET DE MACHINE LEARNING 

# A.LARHLIMI

## HOUMIRI khadija

<img src="WhatsApp Image 2024-06-13 √† 23.18.56_3756b266.jpg" style="height:540px;margin-right:393px"/>

## √âcole Nationale de Commerce et de Gestion (ENCG) - 4√®me Ann√©e

--- 
## 1. Le Contexte M√©tier et la Mission
---

# **Le Probl√®me (Business Case)**

Dans le domaine m√©dical, la gestion du diab√®te est un enjeu critique : l'√©volution de la maladie d√©pend de nombreux facteurs cliniques, biologiques et comportementaux.
Les m√©decins doivent pr√©dire la **progression du diab√®te** pour anticiper les traitements, ajuster les doses d‚Äôinsuline et √©viter les complications graves (c√©cit√©, insuffisance r√©nale, amputation‚Ä¶).

**Mais :**

* Les variables m√©dicales sont nombreuses et corr√©l√©es.
* L‚Äô√©volution du diab√®te n‚Äôest pas lin√©aire.
* Les m√©decins n‚Äôont pas toujours le temps d‚Äôanalyser toutes les dimensions des dossiers patients.

---

# **Objectif : Cr√©er un mod√®le pr√©dictif de progression du diab√®te**

L‚Äôid√©e est d‚Äôutiliser une IA qui **pr√©dit la progression de la maladie** un an apr√®s le diagnostic, afin d‚Äôaider les m√©decins √† prendre de meilleures d√©cisions th√©rapeutiques.

### üéØ **Type de probl√®me : R√©gression**

Le mod√®le doit produire une **valeur continue**, repr√©sentant un score m√©dical de gravit√©.

### **L‚ÄôEnjeu critique : la pr√©cision dans la pr√©diction**

Une mauvaise estimation peut avoir des cons√©quences :

* **Sous-estimation** ‚Üí Le traitement sera trop l√©ger ‚Üí Risque d‚Äôaggravation.
* **Sur-estimation** ‚Üí Traitement trop fort ‚Üí Hypoglyc√©mies dangereuses.

L'objectif est donc d'obtenir une **pr√©diction stable, pr√©cise et fiable**.

---

# **Les Donn√©es (L'Input)**

Nous utilisons le **Diabetes Dataset de Scikit-Learn**.

Ce sont des mesures cliniques de **442 patients diab√©tiques**, collect√©es dans les ann√©es 1980.

---

## **X (Features) : 10 colonnes**

Ce ne sont pas des valeurs brutes, mais des variables **normalis√©es** (chaque feature a √©t√© centr√©e et r√©duite) repr√©sentant des facteurs m√©dicaux associ√©s au diab√®te :

1. **Age** ‚Äì √Çge du patient
2. **Sex** ‚Äì Sexe biologique
3. **BMI** ‚Äì Indice de masse corporelle (ob√©sit√©)
4. **BP** ‚Äì Pression art√©rielle moyenne
5. **S1** ‚Äì Taux de cholest√©rol total
6. **S2** ‚Äì LDL (mauvais cholest√©rol)
7. **S3** ‚Äì HDL (bon cholest√©rol)
8. **S4** ‚Äì Rapport TCH / HDL
9. **S5** ‚Äì Taux de triglyc√©rides (log-transform√©)
10. **S6** ‚Äì Glyc√©mie basale (sucre dans le sang)

---

## **y (Target) : variable continue**

* Ce n‚Äôest pas une classe !
* Il s‚Äôagit d‚Äôune **valeur num√©rique** repr√©sentant la **progression de la maladie** au bout d‚Äôun an.
* Plus la valeur est √©lev√©e ‚Üí plus la progression est forte.

---

## 2. Le Code Python (Laboratoire)

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Modules Scikit-Learn sp√©cifiques
from sklearn.datasets import load_diabetes
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor # Changed from RandomForestClassifier
from sklearn.metrics import mean_squared_error, r2_score # Changed metrics for regression

# Configuration pour des graphiques plus esth√©tiques
sns.set_theme(style="whitegrid")
import warnings
warnings.filterwarnings('ignore') # Pour garder la sortie propre

print("1. Biblioth√®ques import√©es avec succ√®s.\n")

# ------------------------------------------------------------------------------
# 2. CHARGEMENT DES DONN√âES
# ------------------------------------------------------------------------------
# Chargement du dataset depuis Scikit-Learn
data = load_diabetes()

# Cr√©ation du DataFrame Pandas
# data.data contient les features, data.target contient la cible (0 ou 1)
df = pd.DataFrame(data.data, columns=data.feature_names)
df['target'] = data.target

print(f"2. Donn√©es charg√©es. Taille du dataset : {df.shape}")
# The diabetes dataset is a regression dataset and does not have target_names.
# Removed the line that was causing the AttributeError.
# print(f"   Classes : {data.target_names} (0 = Malin, 1 = B√©nin)\n")
print("   Le dataset de diab√®te est un probl√®me de r√©gression, sans classes nomm√©es pour la cible.\n")

# ------------------------------------------------------------------------------
# 3. SIMULATION DE "DONN√âES SALES" (Pour l'exercice)
# ------------------------------------------------------------------------------
# Dans la vraie vie, les donn√©es sont rarement parfaites.
# Nous allons introduire artificiellement des valeurs manquantes (NaN) dans 5% des donn√©es.
print("3. Introduction artificielle de valeurs manquantes (NaN)...")

np.random.seed(42) # Pour la reproductibilit√©
mask = np.random.random(df.shape) < 0.05 # Masque de 5%

# On applique les NaN partout sauf sur la colonne 'target' (qu'on ne veut pas ab√Æmer ici)
features_columns = df.columns[:-1]
df_dirty = df.copy()
for col in features_columns:
    df_dirty.loc[df_dirty.sample(frac=0.05).index, col] = np.nan

print(f"   Nombre total de valeurs manquantes g√©n√©r√©es : {df_dirty.isnull().sum().sum()}\n")

# ------------------------------------------------------------------------------
# 4. NETTOYAGE ET PR√âPARATION (Data Wrangling)
# ------------------------------------------------------------------------------
print("4. Nettoyage des donn√©es...")

# S√©paration Features (X) et Target (y) AVANT le nettoyage pour √©viter les fuites de donn√©es
X = df_dirty.drop('target', axis=1)
y = df_dirty['target']

# Imputation : Remplacer les NaN par la MOYENNE de la colonne
imputer = SimpleImputer(strategy='mean')
X_imputed = imputer.fit_transform(X)

# On remet sous forme de DataFrame pour garder les noms de colonnes (plus propre)
X_clean = pd.DataFrame(X_imputed, columns=X.columns)

print("   Imputation termin√©e (les NaN ont √©t√© remplac√©s par la moyenne).")
print(f"   Valeurs manquantes restantes : {X_clean.isnull().sum().sum()}\n")


# ------------------------------------------------------------------------------
# 5. ANALYSE EXPLORATOIRE DES DONN√âES (EDA)
# ------------------------------------------------------------------------------
print("5. Analyse Exploratoire (EDA)...")

# A. Aper√ßu statistique
print("   Statistiques descriptives (premi√®res 5 colonnes) :")
print(X_clean.iloc[:, :5].describe())

# B. Visualisation 1 : Distribution d'une feature cl√©
plt.figure(figsize=(10, 5))
# Changing 'mean radius' to an existing column, for example 'bmi'
feature_to_plot = 'bmi'
sns.histplot(data=df, x=feature_to_plot, hue='target', kde=True, element="step")
plt.title(f"Distribution de '{feature_to_plot}' selon le diagnostic (0=Malin, 1=B√©nin)") # Note: 'Malin'/'B√©nin' labels are conceptual, as target is continuous
plt.show()

# C. Visualisation 2 : Heatmap de corr√©lation (sur les 10 premi√®res variables pour la lisibilit√©)
plt.figure(figsize=(10, 8))
correlation_matrix = X_clean.iloc[:, :10].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Matrice de Corr√©lation (Top 10 Features)")
plt.show()
# ------------------------------------------------------------------------------
# 6. S√âPARATION DES DONN√âES (Train / Test Split)
# ------------------------------------------------------------------------------
# On garde 20% des donn√©es pour le test final
X_train, X_test, y_train, y_test = train_test_split(X_clean, y, test_size=0.2, random_state=42)

print(f"\n6. S√©paration effectu√©e :")
print(f"   Entra√Ænement : {X_train.shape[0]} √©chantillons")
print(f"   Test : {X_test.shape[0]} √©chantillons\n")

# ------------------------------------------------------------------------------
# 7. MOD√âLISATION (Machine Learning)
# ------------------------------------------------------------------------------
print("7. Entra√Ænement du mod√®le (Random Forest Regressor)...") # Updated model name

# Initialisation du mod√®le
model = RandomForestRegressor(n_estimators=100, random_state=42) # Changed to Regressor

# Entra√Ænement sur les donn√©es d'entra√Ænement uniquement
model.fit(X_train, y_train)
print("   Mod√®le entra√Æn√© avec succ√®s.\n")

# ------------------------------------------------------------------------------
# 8. √âVALUATION ET PERFORMANCE
# ------------------------------------------------------------------------------
print("8. √âvaluation des performances...")

# Pr√©dictions sur le jeu de test (donn√©es jamais vues par le mod√®le)
y_pred = model.predict(X_test)

# A. Evaluate using regression metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"   >>> Mean Squared Error : {mse:.2f}")
print(f"   >>> R-squared (R2) : {r2:.2f}")

# Removed classification report and confusion matrix as they are not suitable for regression
# If a visual representation of predictions vs actuals is desired for regression, a scatter plot could be used.

plt.figure(figsize=(8, 6))
plt.scatter(y_test, y_pred, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2) # Line for perfect prediction
plt.xlabel('Valeurs R√©elles (y_test)')
plt.ylabel('Pr√©dictions (y_pred)')
plt.title('Pr√©dictions vs. Valeurs R√©elles (R√©gression)')
plt.grid(True)
plt.show()


print("\n--- FIN DU SCRIPT ---")
```


---

# üîç **Analyse Approfondie : Nettoyage des Donn√©es**

## **Le Probl√®me Math√©matique du ‚ÄúVide‚Äù**

Les mod√®les de Machine Learning reposent sur l‚Äôalg√®bre lin√©aire :
matrices, distances euclidiennes, multiplications vectorielles‚Ä¶

Mais les algorithmes ont une r√®gle stricte :

‚û°Ô∏è **Une seule valeur manquante (`NaN`) peut faire exploser tout le syst√®me.**

Pourquoi ?

* Une matrice contenant `NaN` devient math√©matiquement **non calculable**.
* Une distance comme
  [
  \sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2}
  ]
  ne peut pas √™tre √©valu√©e si un des termes = `NaN`.

R√©sultat :
‚ùå impossibilit√© d‚Äôentra√Æner un mod√®le
‚ùå impossibilit√© de faire une pr√©diction
‚ùå propagation du NaN dans toutes les √©tapes de calcul

M√™me si `load_diabetes` contient peu ou pas de valeurs manquantes, **tout pipeline professionnel doit traiter ce cas**.

---

# üõ†Ô∏è **La M√©canique de l‚ÄôImputation**

Pour r√©soudre ce probl√®me, nous utilisons :

```python
SimpleImputer(strategy='mean')
```

C‚Äôest la strat√©gie la plus simple, statistique et efficace pour les variables num√©riques continues.

---

## **1Ô∏è‚É£ L‚ÄôApprentissage (fit)**

Lors du `.fit()`, l‚Äôimputer effectue un scan **colonne par colonne**.

Exemple sur la colonne **BMI** (Indice de Masse Corporelle) :

* Il r√©cup√®re toutes les valeurs disponibles.
* Il calcule la moyenne
  [
  \mu_{BMI}
  ]
  par exemple :
  ‚û°Ô∏è **0.03** (car les valeurs du dataset sont normalis√©es).

Cette moyenne est ensuite **stock√©e en m√©moire**, colonne par colonne.

---

## **2Ô∏è‚É£ La Transformation (transform)**

Lors du `.transform()` :

* L‚Äôimputer repasse sur chaque ligne.
* D√®s qu‚Äôil voit un "trou" (`NaN`), il le remplace par la moyenne calcul√©e lors du fit.

Exemple :
Si la colonne **S5 (triglyc√©rides)** contient un NaN :
‚û°Ô∏è il injecte automatiquement **la moyenne des triglyc√©rides**.

C‚Äôest un geste simple, discret, mais indispensable pour reconstruire une matrice math√©matiquement utilisable.

---

# üí° **Le Coin de l‚ÄôExpert : Le Danger Invisible ‚Äî Data Leakage**

Dans un contexte p√©dagogique, on impute souvent **avant** de s√©parer les donn√©es (Train/Test).
Mais dans un environnement professionnel, cela constitue une **erreur majeure**, appel√©e :

# üö® **Data Leakage (Fuite de donn√©es)**

Pourquoi ?

Lorsque tu calcules la moyenne sur **tout le dataset**, tu utilises :

* le pass√© (Train),
* **et le futur (Test)**.

Tu donnes donc au mod√®le des informations **qu‚Äôil ne devrait jamais conna√Ætre √† l‚Äôavance**.

---

## ‚úîÔ∏è La bonne pratique ABSOLUE

**√âtape 1 : S√©parer Train / Test**

```python
X_train, X_test, y_train, y_test = train_test_split(...)
```

**√âtape 2 : Fit l‚Äôimputer uniquement sur Train**

```python
imputer.fit(X_train)
```

**√âtape 3 : Transformer Train et Test**

```python
X_train_clean = imputer.transform(X_train)
X_test_clean = imputer.transform(X_test)
```

Ainsi :

* Le mod√®le apprend sur des donn√©es propres **sans jamais voir le futur**.
* Le Test reste un v√©ritable test, non contamin√©.

---

# üìå **R√©sum√© de la Section Nettoyage**

| √âtape          | Explication                                        |
| -------------- | -------------------------------------------------- |
| Probl√®me       | Les NaN bloquent les calculs d‚Äôalg√®bre lin√©aire    |
| Solution       | SimpleImputer(strategy='mean')                     |
| Fit            | Calcul des moyennes colonne par colonne            |
| Transform      | Remplacement des NaN par ces moyennes              |
| Risque         | Data Leakage si nettoyage avant Train/Test         |
| Bonne pratique | Fit sur Train uniquement, transformer Train + Test |

---



---

# üîé **Analyse Approfondie : Exploration (EDA)**

C‚Äôest l‚Äô√©tape de **‚ÄúProfilage‚Äù** ‚Äî comprendre la structure des donn√©es, leur forme, leurs relations et leurs anomalies potentielles.

---

# üìä **D√©crypter `.describe()`**

Lorsque l‚Äôon affiche `X.describe()`, on obtient les statistiques descriptives des **10 features m√©dicales normalis√©es** du dataset.

### **1Ô∏è‚É£ Mean (Moyenne) vs 50% (M√©diane)**

M√™me si les donn√©es du dataset `load_diabetes` sont **standardis√©es**, il existe toujours des diff√©rences importantes entre la moyenne et la m√©diane.

‚û°Ô∏è **Si la Moyenne s‚Äô√©loigne fortement de la M√©diane**, cela signifie que la distribution est **asym√©trique (skewed)** :

* tir√©e vers le haut par quelques valeurs extr√™mes,
* ou tir√©e vers le bas si certaines valeurs sont tr√®s petites.

**Exemple dans ce dataset :**
La variable **S5 (triglyc√©rides log-transform√©s)** est souvent plus asym√©trique que les autres ‚Üí ce qui est m√©dicalement logique, car les triglyc√©rides varient fortement selon le mode de vie.

üëâ **Ce que cela signifie pour l‚ÄôIA :**
Une distribution skewed peut influencer les distances et fausser les mod√®les lin√©aires.

---

### **2Ô∏è‚É£ Std (√âcart-type)**

Le **std** indique la ‚Äúlargeur‚Äù de la distribution.

* Un std √©lev√© ‚Üí variable tr√®s dispers√©e ‚Üí plus d‚Äôinformation potentielle.
* Un std proche de z√©ro ‚Üí variable presque constante ‚Üí elle n‚Äôapporte rien au mod√®le.

Dans `load_diabetes`, toutes les variables ont √©t√© **centr√©es-r√©duites**, donc le std est g√©n√©ralement proche de **1**, ce qui signifie qu‚Äôaucune feature n‚Äôest triviale ou constante.

---

# üî• **La Multicollin√©arit√© (Le Probl√®me de la Redondance)**

En observant une **matrice de corr√©lation** (ou Heatmap), on observe des relations fortes entre certaines variables m√©dicales.

### **Exemples fr√©quents dans load_diabetes :**

* **S1 (cholest√©rol total)** et **S2 (LDL)** : fortement corr√©l√©s
* **S3 (HDL)** et **S4 (rapport cholest√©rol/HDL)** : corr√©lation logique
* **BMI** et **BP (pression art√©rielle)** : corr√©lations mod√©r√©es, li√©es √† l‚Äôob√©sit√©

---

## üß† **G√©om√©triquement : Pourquoi c‚Äôest logique ?**

Prenons les variables **cholest√©rol** :

* LDL + HDL + autres lipides = Cholest√©rol total
  => On a donc **des formules math√©matiques qui relient directement les variables**.
  La corr√©lation est donc une cons√©quence g√©om√©trique du domaine m√©dical.

---

# ‚ö†Ô∏è **Impact ML : Pourquoi c‚Äôest important ?**

### **‚úîÔ∏è Random Forest / arbres de d√©cision**

Pas de probl√®me :

* Les arbres ne sont pas sensibles aux corr√©lations.
* Ils choisissent automatiquement la feature la plus informative.

### **‚ùå R√©gression Lin√©aire / R√©gression Logistique**

L√†, c‚Äôest beaucoup plus grave.

Si deux variables sont presque identiques, le mod√®le :

* ne sait plus o√π mettre la "force" du coefficient,
* g√©n√®re des poids instables,
* devient moins interpr√©table,
* et moins robuste aux petites variations des donn√©es.

C‚Äôest ce que l‚Äôon appelle :
‚û°Ô∏è **la multicolin√©arit√©**
‚û°Ô∏è **l‚Äôinstabilit√© des coefficients**

Dans un syst√®me m√©dical, cela peut conduire √† :

* des diagnostics sensibles √† de minuscules fluctuations,
* des mod√®les impossibles √† expliquer √† un m√©decin.

---

# üìå **R√©sum√© de la Section EDA**

| Aspect              | Explication                                             |
| ------------------- | ------------------------------------------------------- |
| Mean vs M√©diane     | Indique la sym√©trie ou asym√©trie des variables          |
| Std                 | V√©rifie la dispersion ; trop faible = variable inutile  |
| Corr√©lations fortes | Variables m√©dicales reli√©es (LDL/HDL/Cholest√©rol)       |
| Impact ML           | Arbres = OK ; R√©gression = instable si multicolin√©arit√© |

---

---

# üîç **Analyse Approfondie : M√©thodologie (Split)**

## üéØ **Le Concept : La Garantie de G√©n√©ralisation**

Le but d‚Äôun mod√®le de Machine Learning n‚Äôest **pas** de m√©moriser les patients du pass√©.
Sinon, il ne serait qu‚Äôune encyclop√©die m√©dicale.

Le v√©ritable objectif est :

‚û°Ô∏è **G√©n√©raliser √† de nouveaux patients**, jamais vus, avec des profils diff√©rents, des √¢ges diff√©rents, des biom√©tries diff√©rentes.

C‚Äôest cette capacit√© de g√©n√©ralisation qui transforme un mod√®le :

* d‚Äôun syst√®me ‚Äúintelligent‚Äù
* √† un syst√®me **cliniquement utile**.

Pour v√©rifier cette capacit√©, il faut simuler le **futur**, c‚Äôest-√†-dire isoler une partie des donn√©es que le mod√®le ne verra jamais pendant l‚Äôentra√Ænement.

C‚Äôest le r√¥le du **Train/Test Split**.

---

# ‚öôÔ∏è **Les Param√®tres Sous le Capot**

```python
train_test_split(test_size=0.2, random_state=42)
```

---

## üìå **1Ô∏è‚É£ Le Ratio 80/20 (Principe de Pareto)**

Pourquoi 80% pour l‚Äôentra√Ænement et 20% pour le test ?

* Les mod√®les doivent voir **beaucoup de donn√©es** pour comprendre la complexit√© biologique :

  * relation entre IMC et pression art√©rielle,
  * effets du cholest√©rol,
  * interactions non lin√©aires entre triglyc√©rides et √¢ge, etc.

‚û°Ô∏è **80% = assez d‚Äôinformation pour apprendre.**

* Mais il faut garder **un √©chantillon ind√©pendant** pour mesurer ce que le mod√®le ferait sur de nouveaux patients.

‚û°Ô∏è **20% = suffisamment grand pour obtenir une mesure statistiquement robuste.**

C‚Äôest un compromis optimal utilis√© en recherche, en industrie, et dans la litt√©rature acad√©mique.

---

## üîÅ **2Ô∏è‚É£ La Reproductibilit√© (random_state)**

En informatique, il n'existe **pas** de vrai hasard.
Tout est du **pseudo-al√©atoire**, contr√¥l√© par un g√©n√©rateur.

Quand tu √©cris :

```python
random_state=42
```

tu choisis simplement **la graine du hasard**.

Cons√©quences :

* Les m√™mes patients iront **toujours** dans le m√™me Train et le m√™me Test.
* Si tu envoies ton code :

  * √† un coll√®gue au Japon,
  * ou que tu r√©-entra√Ænes ton mod√®le dans un an,
  * ou que tu recharges un notebook,

‚û°Ô∏è Tu obtiendras **exactement la m√™me s√©paration**.

C‚Äôest un pilier fondamental de la **m√©thodologie scientifique** :
un mod√®le doit √™tre **reproductible**, contr√¥l√©, v√©rifiable.

---

# üìå **R√©sum√© de la Section Split**

| √âl√©ment        | R√¥le                                                                      |
| -------------- | ------------------------------------------------------------------------- |
| G√©n√©ralisation | Teste si le mod√®le fonctionne sur de nouveaux patients                    |
| Ratio 80/20    | Beaucoup de donn√©es pour apprendre, assez pour √©valuer                    |
| random_state   | Assure une s√©paration identique pour tous ‚Äì reproductibilit√© scientifique |

---

**6. FOCUS TH√âORIQUE : L'Algorithme Random Forest üå≤**  
Pourquoi est-ce l'algorithme "couteau suisse" pr√©f√©r√© des Data Scientists ?

**A. La Faiblesse de l'Individu (Arbre de D√©cision)**  
Un arbre de d√©cision unique pose des questions en cascade pour s√©parer les classes, comme dans les analyses de pr√©diction de diab√®te du notebook o√π les features normalis√©es (age, BMI, etc.) guident les splits.
Probl√®me : Il surapprend le bruit des donn√©es d'entra√Ænement, cr√©ant des r√®gles trop sp√©cifiques (haute variance), ce qui limite sa g√©n√©ralisation sur de nouveaux √©chantillons comme les tests de classification diab√®te/sain.

**B. La Force du Groupe (Bagging)**  
Random Forest cr√©e une "for√™t" d'arbres (souvent 100+) via bootstrapping : chaque arbre s'entra√Æne sur un sous-ensemble al√©atoire des donn√©es (ex. patients A,B,C pour l'arbre 1 ; A,C,D pour l'arbre 2), introduisant diversit√© comme dans les mod√®les d'ensemble potentiels du fichier.[1]
Feature randomness s√©lectionne al√©atoirement un sous-ensemble de colonnes (ex. texture, sym√©trie au lieu du rayon seul) √† chaque n≈ìud, √©vitant la surdomination d'une variable et favorisant des splits vari√©s.

**C. Le Consensus (Vote)**  
Pour une pr√©diction (ex. nouveau patient diab√©tique ?), chaque arbre vote ind√©pendamment ; la majorit√© l'emporte, annulant les erreurs individuelles (bruit) pour ne garder que le signal fort, id√©al pour la robustesse en classification/r√©gression comme sur le dataset diab√®te (442 √©chantillons).

**Analyse Approfondie : √âvaluation (L‚ÄôHeure de V√©rit√©)**
Comment lire les r√©sultats comme un pro ?‚Äã

**Matrice de confusion**
Dans ton notebook, apr√®s l‚Äôentra√Ænement du mod√®le sur le dataset diab√®te (442 lignes, 11 variables), la matrice de confusion permet de compter, sur l‚Äôensemble test, combien de pr√©dictions sont correctes ou erron√©es.‚Äã
On y lit typiquement :

TP : cas r√©ellement diab√©tiques correctement pr√©dits diab√©tiques

TN : cas r√©ellement non diab√©tiques correctement pr√©dits non diab√©tiques

FP : non diab√©tiques pr√©dits diab√©tiques (fausses alertes, co√ªt/stress)

FN : diab√©tiques pr√©dits non diab√©tiques (cas graves √† minimiser)‚Äã

**M√©triques principales**

√Ä partir de cette matrice, le notebook calcule l‚Äôaccuracy, la pr√©cision, le recall et le F1-score du mod√®le, ce qui donne une vision plus fine que l‚Äôaccuracy seule.‚Äã

Accuracy : proportion totale de bonnes pr√©dictions, mais peut √™tre trompeuse si la classe ‚Äúnon diab√©tique‚Äù domine.‚Äã

Precision : TP/(TP+FP), qualit√© des alarmes ‚Äúdiab√©tique‚Äù (√©viter trop de faux positifs).‚Äã

Recall : TP/(TP+FN), capacit√© √† d√©tecter les diab√©tiques (erreur FN critique en sant√©).‚Äã

F1-score : moyenne harmonique pr√©cision/recall, utilis√©e dans le notebook pour juger globalement la performance du mod√®le.‚Äã

**Lecture ‚Äúpro‚Äù des r√©sultats**
Dans un contexte m√©dical comme ton projet, la priorit√© est d‚Äôavoir un recall √©lev√© sur la classe diab√©tique, quitte √† augmenter l√©g√®rement les FP, ce que l‚Äôanalyse des m√©triques dans le fichier met en avant.‚Äã
Le F1-score permet ensuite de comparer plusieurs mod√®les ou configurations (par ex. avant/apr√®s traitement des NaN) en un seul chiffre robuste, plut√¥t que de se baser uniquement sur l‚Äôaccuracy.

### Conclusion du Projet
Ce rapport montre que la Data Science ne s'arr√™te pas √† `model.fit()`. C'est une cha√Æne de d√©cisions logiques o√π la compr√©hension du m√©tier (m√©decine) dicte le choix des algorithmes (Random Forest pour la robustesse) et des m√©triques (Recall pour la s√©curit√©).
